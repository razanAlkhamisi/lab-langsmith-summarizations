{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52bb9c6d-7a1c-480a-93c9-acf847773163",
      "metadata": {
        "id": "52bb9c6d-7a1c-480a-93c9-acf847773163"
      },
      "source": [
        "# Lab | Summarization evaluation using LangSmith\n",
        "Let's revisit your capstone project 2? Well, sort of. Pick diffierent sets of data and re-run this notebook. Maybe parts of the dataset you used in your last project week. The point is for you to understand all steps involve and the many different ways one can and should evaluate LLM applications using LangSmith.\n",
        "\n",
        "What did you learn? - Let's discuss that in class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9",
      "metadata": {
        "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9"
      },
      "source": [
        "## LangSmith - LangChain evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa_XBi5wdjsL",
        "outputId": "e37d337c-2b09-4a50-a5d9-1563997c7e97"
      },
      "id": "Sa_XBi5wdjsL",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.53 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.55)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.75.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (0.3.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (2.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.53->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain_openai) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain_openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain_openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.3.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT4oY_FtdTqP",
        "outputId": "a87d7282-70eb-4c7a-cf15-a632cb45467d"
      },
      "id": "BT4oY_FtdTqP",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqghbRxlcvH4",
        "outputId": "21346970-c960-4a03-8ec9-59888c4d7aeb"
      },
      "id": "bqghbRxlcvH4",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.55)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.24)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.33)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain_community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain_community) (2.33.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.22-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.22 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nDyCSpyRD2l",
        "outputId": "4236c348-009b-4afe-809d-4deefb660096"
      },
      "id": "-nDyCSpyRD2l",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXhPJQvwQXzq",
        "outputId": "ed2512a0-b7d6-44e4-dfe0-07ae414aa7e8"
      },
      "id": "wXhPJQvwQXzq",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (0.9.9)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
      "metadata": {
        "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
        "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
      "metadata": {
        "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"langsmith_max-test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
      "metadata": {
        "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Importing Client from Langsmith\n",
        "from langsmith import Client\n",
        "client = Client(api_key=LANGCHAIN_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2",
      "metadata": {
        "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2"
      },
      "source": [
        "### Create Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
      "metadata": {
        "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"gigaword\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da",
      "metadata": {
        "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def add_prefix(example):\n",
        "    return {\n",
        "        **example,\n",
        "        \"article\": f\"Summarize this news:\\n{example['article']}\"\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "3b54b146-e870-4721-a0ae-03401d52d8ac",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b54b146-e870-4721-a0ae-03401d52d8ac",
        "outputId": "dd07f9e2-5406-4f92-e2f2-49a9df394bcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document', 'summary'],\n",
              "        num_rows: 3803957\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['document', 'summary'],\n",
              "        num_rows: 189651\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document', 'summary'],\n",
              "        num_rows: 1951\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "4925ad37-55f3-44b1-9c46-3adcc8c58942",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4925ad37-55f3-44b1-9c46-3adcc8c58942",
        "outputId": "28d7b4af-9d93-4a64-d731-f553a207caae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': \"australia 's current account deficit shrunk by a record #.## billion dollars -lrb- #.## billion us -rrb- in the june quarter due to soaring commodity prices , figures released monday showed .\",\n",
              " 'summary': 'australian current account deficit narrows sharply'}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "f12ac5863460481a9846e48e183907a3",
            "65238e19df25438584781a4c469d67e3",
            "d351d74e9b624a99a543fd00ea0600e2",
            "9b49b7a6bb0840ab9d3c7f6ef7114c80",
            "2cf81fecdcfd4683a207979ec3a330f2",
            "45515b48b23041778682fce20e43d7bb",
            "81ad7cc653e84c0182c9591c1b51ce94",
            "e4655d1a047346c3bb5ab5c1325a23df",
            "832c4321c0bb44c2afa9102a4c7d43fd",
            "8943fd40fda74fab8935b623d57fbf78",
            "6982f9c9a5ba4e3e8d772854870877db"
          ]
        },
        "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
        "outputId": "043d240a-f7a1-4e28-f7c6-c9ccf331385d",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f12ac5863460481a9846e48e183907a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'document': \"japan 's nec corp. and UNK computer corp. of the united states said wednesday they had agreed to join forces in supercomputer sales .\", 'summary': 'nec UNK in computer sales tie-up'}\n"
          ]
        }
      ],
      "source": [
        "def add_prefix(example):\n",
        "    example[\"document\"] = \"summarize: \" + example[\"document\"]\n",
        "\n",
        "# Select a small sample for testing\n",
        "MAX_NEWS = 10\n",
        "sample = dataset[\"test\"].select(range(MAX_NEWS)).map(add_prefix)\n",
        "\n",
        "# View the sample\n",
        "print(sample[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc0ef576-ea25-446d-a99b-354678a274ba",
      "metadata": {
        "id": "bc0ef576-ea25-446d-a99b-354678a274ba"
      },
      "source": [
        "The dataset contains three columns: article, highlights, and id. To use LangSmith, we need to create a dataset in LangSmith format.\n",
        "\n",
        "LangSmith expects a prompt and a result. To achieve this, we will transform the article into a prompt by adding the prefix: \"Summarize this news.\" As a result, we will use the content of highlights, which represents the summaries created by humans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
        "outputId": "f598171a-330b-4682-bc2a-65d8e66e45c5",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'document': \"japan 's nec corp. and UNK computer corp. of the united states said wednesday they had agreed to join forces in supercomputer sales .\", 'summary': 'nec UNK in computer sales tie-up'}\n"
          ]
        }
      ],
      "source": [
        "print(sample[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8",
      "metadata": {
        "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8"
      },
      "source": [
        "Now We have the Dataset with the prompt and the Reference Summary, it is time to create a Dataset in LangSmith with this information.\n",
        "### Create the Dataset in Langsmith\n",
        "\n",
        "The dataset in LangSmith is composed of an input, which is the prompt passed to the model for evaluation, and an output, which should contain what we expect the model to return."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0",
      "metadata": {
        "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "221d8e92-c2f1-499c-9e68-3abb752722c4",
      "metadata": {
        "id": "221d8e92-c2f1-499c-9e68-3abb752722c4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "input_key=['article']\n",
        "output_key=['highlights']\n",
        "\n",
        "NAME_DATASET=f\"Summarize_dataset_{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "aa3c7713d43e4eec89d4628a6aedb7e6",
            "c79430ee5703487e9dae7ead8aea66f0",
            "0ccc224a64844391ae80c3450ee9cbd8",
            "4b7c21c7798948b6b4d2dbebcd9de02a",
            "2f9bbfa9db3c493596cd778b3cc81805",
            "f6236d375891449e9c477c57db5bdb5c",
            "ce39349f63314547952efcd326f3e6ed",
            "68a84666ad114e1f968746cf248e658e",
            "094a919dd43443ef9663dd48dc133e96",
            "4cf1967d60f14d68b94da1fcc170a784",
            "fd5ad424cbbb4302849ff3890172598e"
          ]
        },
        "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
        "outputId": "be7cf60f-a49d-44ef-a729-b26247fc3b16",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa3c7713d43e4eec89d4628a6aedb7e6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Set keys\n",
        "input_key = [\"input\"]\n",
        "output_key = [\"summary\"]\n",
        "\n",
        "# Unique dataset name\n",
        "NAME_DATASET = f\"embedding-test-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "\n",
        "# Rename the 'document' column to 'input' before uploading\n",
        "sample = sample.rename_column(\"document\", \"input\")\n",
        "\n",
        "# Upload\n",
        "dataset = client.upload_dataframe(\n",
        "    df=sample,\n",
        "    input_keys=input_key,\n",
        "    output_keys=output_key,\n",
        "    name=NAME_DATASET,\n",
        "    description=\"Test Embedding distance between model summarizations\",\n",
        "    data_type=\"kv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada2bd55-b6bc-467c-b481-48d46ad50441",
      "metadata": {
        "id": "ada2bd55-b6bc-467c-b481-48d46ad50441"
      },
      "source": [
        "In this image, we can see an example from the dataset once it's been registered in LangSmith.\n",
        "\n",
        "In the Input column, there is the prompt to be sent, while in the Output column, the expected output is stored.\n",
        "\n",
        "When performing the comparison, the model will be given the prompt, and the Cosine distance between its response and the one stored in the sample dataset will be calculated.\n",
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Dataset.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8278f53f-1a94-407c-846d-05c926737704",
      "metadata": {
        "id": "8278f53f-1a94-407c-846d-05c926737704"
      },
      "source": [
        "### Recovering Models From Hugging Face\n",
        "Let's retrieve both models from HuggingFace. A base T5 model and a model that has been fine-tuned using the training portion of this same dataset to generate summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421",
      "metadata": {
        "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8",
      "metadata": {
        "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e76599-7c52-46a8-deb7-d12e40e6f353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-115-abc985856e79>:1: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  summarizer_base = HuggingFaceHub(\n"
          ]
        }
      ],
      "source": [
        "summarizer_base = HuggingFaceHub(\n",
        "    repo_id=\"t5-base\",\n",
        "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df",
      "metadata": {
        "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df",
        "tags": []
      },
      "outputs": [],
      "source": [
        "summarizer_finetuned = HuggingFaceHub(\n",
        "    repo_id=\"flax-community/t5-base-cnn-dm\",\n",
        "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6",
      "metadata": {
        "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6"
      },
      "source": [
        "## Defining Evaluator\n",
        "The first step is to define an evaluator, where we specify the variables we want to evaluate. In our case, I have chosen to measure only the \"embedding_distance.\"\n",
        "\n",
        "I've left the \"string_distance\" as a comment in case you want to conduct a test with two evaluations instead of one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "d506d770-2c30-41a6-acde-283ad1b27ea9",
      "metadata": {
        "id": "d506d770-2c30-41a6-acde-283ad1b27ea9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.smith import run_on_dataset, RunEvalConfig\n",
        "# !pip install -q rapidfuzz==3.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d",
      "metadata": {
        "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#We are using just one of the multiple evaluator avaiable on LangSmith.\n",
        "\n",
        "evaluation_config = RunEvalConfig(\n",
        "    evaluators=[\n",
        "        \"embedding_distance\",\n",
        "        #\"string_distance\"\n",
        "    ],\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee666c30-d958-45b1-802c-7034dd13b42b",
      "metadata": {
        "id": "ee666c30-d958-45b1-802c-7034dd13b42b"
      },
      "source": [
        "### Running Evaluator\n",
        "With the same configuration, we can launch two evaluations on the same dataset. One for each of the chosen models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "67c75c07-8351-465f-af15-a1abe17968f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67c75c07-8351-465f-af15-a1abe17968f9",
        "outputId": "bd87557c-26c4-4e09-e687-13d9ec40e79f",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'T5-BASE 2025-04-25 14:58:53' at:\n",
            "https://smith.langchain.com/o/57863e78-aca7-4f7b-ba6c-39633a72b998/datasets/08e6c11c-bb39-4b96-bf31-12227fae83df/compare?selectedSessions=af4022fa-b38f-4763-a276-a729b677ab33\n",
            "\n",
            "View all tests for Dataset embedding-test-20250425-145458 at:\n",
            "https://smith.langchain.com/o/57863e78-aca7-4f7b-ba6c-39633a72b998/datasets/08e6c11c-bb39-4b96-bf31-12227fae83df\n",
            "[>                                                 ] 0/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[---->                                             ] 1/10\r[--------->                                        ] 2/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[-------------->                                   ] 3/10\r[------------------->                              ] 4/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------>                         ] 5/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[------------------------------------------------->] 10/10"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "project_name = f\"T5-BASE {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "base_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=summarizer_base,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
        "outputId": "8a113275-cfff-4c22-e810-a10bcd216425",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'T5-FineTuned 2025-04-25 14:59:24' at:\n",
            "https://smith.langchain.com/o/57863e78-aca7-4f7b-ba6c-39633a72b998/datasets/08e6c11c-bb39-4b96-bf31-12227fae83df/compare?selectedSessions=50b3e9c4-6183-4912-be63-093e37130e9c\n",
            "\n",
            "View all tests for Dataset embedding-test-20250425-145458 at:\n",
            "https://smith.langchain.com/o/57863e78-aca7-4f7b-ba6c-39633a72b998/datasets/08e6c11c-bb39-4b96-bf31-12227fae83df\n",
            "[>                                                 ] 0/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 55da9039-8379-4a9d-a10c-bb64398acc76 with inputs {'input': 'the bank of japan appealed to financial markets to remain calm friday following the us decision to order daiwa bank ltd. to close its us operations .'}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 37a4ffda-4d87-4cba-bbb6-2d4ad4c4f1b9 with inputs {'input': 'factory orders for manufactured goods rose #.# percent in september , the commerce department said here thursday .'}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[---->                                             ] 1/10\r[--------->                                        ] 2/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 28a23641-cda6-4fd3-bd23-37630930a2a2 with inputs {'input': 'UNK'}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 35d7b7c6-08c0-4def-97c4-3e189d398f9b with inputs {'input': \"indian prime minister p.v. narasimha rao 's promise of more autonomy for troubled kashmir and his plea for early state elections has sparked a violent reaction from provincial moslem and opposition parties .\"}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[-------------->                                   ] 3/10\r[------------------->                              ] 4/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 202f2a49-5083-4f2f-bf69-dee7f5f4b75e with inputs {'input': \"israel prepared sunday for prime minister yitzhak rabin 's state funeral which will be attended by a host of world leaders , including us president bill clinton and the jordanian and egyptian heads of state .\"}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------>                         ] 5/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 6ce09c5f-8b63-4619-b5cd-f2bd4f9ec06e with inputs {'input': 'croatian president franjo tudjman said friday croatian and serb negotiators would meet saturday to thrash out an agreement on the last serb-held area in croatia , under a deal reached at us-brokered talks .'}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 93f1a3f4-553c-4285-8d2d-509fe4fa6c0a with inputs {'input': \"japan 's toyota team europe were banned from the world rally championship for one year here on friday in a crushing ruling by the world council of the international automobile federation -lrb- fia -rrb- .\"}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example aa34b19c-03e8-4dae-9ee0-57aa0c73fffd with inputs {'input': 'the sri lankan government on wednesday announced the closure of government schools with immediate effect as a military campaign against tamil separatists escalated in the north of the country .'}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------------------->                    ] 6/10\r[---------------------------------->               ] 7/10\r[--------------------------------------->          ] 8/10"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example c966d36c-c52f-44de-9ae1-6a3a6e084835 with inputs {'input': \"japan 's nec corp. and UNK computer corp. of the united states said wednesday they had agreed to join forces in supercomputer sales .\"}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example f53df0e0-da66-4c52-bde2-fd498d4437a1 with inputs {'input': 'police arrested five anti-nuclear protesters thursday after they sought to disrupt loading of a french antarctic research and supply vessel , a spokesman for the protesters said .'}\n",
            "Error Type: HfHubHTTPError, Message: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[-------------------------------------------->     ] 9/10\r[------------------------------------------------->] 10/10"
          ]
        }
      ],
      "source": [
        "#Ignore the error shown below\n",
        "project_name = f\"T5-FineTuned {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "finetuned_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=summarizer_finetuned,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159",
      "metadata": {
        "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159"
      },
      "source": [
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Tests.jpg?raw=true\">\n",
        "\n",
        "In the image below you can see the comparision between two tests.\n",
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareTestst.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xn6jeX7u_4MR",
      "metadata": {
        "id": "Xn6jeX7u_4MR"
      },
      "source": [
        "Well, since it has been so straightforward, why don't we try to make the comparison with an OpenAI model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "84a97ac1-623e-4d28-a78b-c807af89c918",
      "metadata": {
        "id": "84a97ac1-623e-4d28-a78b-c807af89c918"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "open_aillm=OpenAI(temperature=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "suc0G-9W94Qj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suc0G-9W94Qj",
        "outputId": "1c2da14f-99b9-4c25-e5c8-765e397c1e5a",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'OpenAI 2025-04-25 15:00:06' at:\n",
            "https://smith.langchain.com/o/57863e78-aca7-4f7b-ba6c-39633a72b998/datasets/08e6c11c-bb39-4b96-bf31-12227fae83df/compare?selectedSessions=ea1ec69c-6891-4bed-a713-47f364ba8396\n",
            "\n",
            "View all tests for Dataset embedding-test-20250425-145458 at:\n",
            "https://smith.langchain.com/o/57863e78-aca7-4f7b-ba6c-39633a72b998/datasets/08e6c11c-bb39-4b96-bf31-12227fae83df\n",
            "[------------------------------------------------->] 10/10"
          ]
        }
      ],
      "source": [
        "project_name = f\"OpenAI {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "finetuned_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=open_aillm,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B15V_-3pBvOK",
      "metadata": {
        "id": "B15V_-3pBvOK"
      },
      "source": [
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareOpenAI_HF.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fUeZWvLMCOBw",
      "metadata": {
        "id": "fUeZWvLMCOBw"
      },
      "source": [
        "The experiment with the OpenAI model has yielded the best results. But, be aware! As we can see, there is a cost involved since we are using an API, and it needs to be paid for.\n",
        "\n",
        "Another crucial piece of information is that we can view performance data for the models. This data could also be useful for minimally evaluating our inference server."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f12ac5863460481a9846e48e183907a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65238e19df25438584781a4c469d67e3",
              "IPY_MODEL_d351d74e9b624a99a543fd00ea0600e2",
              "IPY_MODEL_9b49b7a6bb0840ab9d3c7f6ef7114c80"
            ],
            "layout": "IPY_MODEL_2cf81fecdcfd4683a207979ec3a330f2"
          }
        },
        "65238e19df25438584781a4c469d67e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45515b48b23041778682fce20e43d7bb",
            "placeholder": "​",
            "style": "IPY_MODEL_81ad7cc653e84c0182c9591c1b51ce94",
            "value": "Map: 100%"
          }
        },
        "d351d74e9b624a99a543fd00ea0600e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4655d1a047346c3bb5ab5c1325a23df",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_832c4321c0bb44c2afa9102a4c7d43fd",
            "value": 10
          }
        },
        "9b49b7a6bb0840ab9d3c7f6ef7114c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8943fd40fda74fab8935b623d57fbf78",
            "placeholder": "​",
            "style": "IPY_MODEL_6982f9c9a5ba4e3e8d772854870877db",
            "value": " 10/10 [00:00&lt;00:00, 778.51 examples/s]"
          }
        },
        "2cf81fecdcfd4683a207979ec3a330f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45515b48b23041778682fce20e43d7bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81ad7cc653e84c0182c9591c1b51ce94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4655d1a047346c3bb5ab5c1325a23df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "832c4321c0bb44c2afa9102a4c7d43fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8943fd40fda74fab8935b623d57fbf78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6982f9c9a5ba4e3e8d772854870877db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa3c7713d43e4eec89d4628a6aedb7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c79430ee5703487e9dae7ead8aea66f0",
              "IPY_MODEL_0ccc224a64844391ae80c3450ee9cbd8",
              "IPY_MODEL_4b7c21c7798948b6b4d2dbebcd9de02a"
            ],
            "layout": "IPY_MODEL_2f9bbfa9db3c493596cd778b3cc81805"
          }
        },
        "c79430ee5703487e9dae7ead8aea66f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6236d375891449e9c477c57db5bdb5c",
            "placeholder": "​",
            "style": "IPY_MODEL_ce39349f63314547952efcd326f3e6ed",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "0ccc224a64844391ae80c3450ee9cbd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a84666ad114e1f968746cf248e658e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_094a919dd43443ef9663dd48dc133e96",
            "value": 1
          }
        },
        "4b7c21c7798948b6b4d2dbebcd9de02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cf1967d60f14d68b94da1fcc170a784",
            "placeholder": "​",
            "style": "IPY_MODEL_fd5ad424cbbb4302849ff3890172598e",
            "value": " 1/1 [00:00&lt;00:00, 47.87ba/s]"
          }
        },
        "2f9bbfa9db3c493596cd778b3cc81805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6236d375891449e9c477c57db5bdb5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce39349f63314547952efcd326f3e6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68a84666ad114e1f968746cf248e658e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094a919dd43443ef9663dd48dc133e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cf1967d60f14d68b94da1fcc170a784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd5ad424cbbb4302849ff3890172598e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}